{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as backend\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from threading import Thread\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('E:\\\\projects\\\\carla\\\\WindowsNoEditor\\\\PythonAPI\\\\carla\\\\dist\\\\carla-0.9.9-py3.7-win-amd64.egg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH = 640\n",
    "IM_HEIGHT = 480\n",
    "SHOW_PREVIEW = False\n",
    "SECONDS_PER_EPISODE = 10\n",
    "REPLAY_MEMORY_SIZE = 5_000\n",
    "MIN_REPLAY_MEMORY_SIZE = 1_000\n",
    "MINIBATCH_SIZE = 16\n",
    "PREDICTION_BATCH_SIZE = 1\n",
    "TRAINING_BATCH_SIZE = MINIBATCH_SIZE // 4\n",
    "UPDATE_TARGET_EVERY = 5\n",
    "MODEL_NAME = 'Xception'\n",
    "\n",
    "MEMORY_FRACTION = 0.6\n",
    "MIN_REWARD = -200\n",
    "\n",
    "EPISODES = 100\n",
    "\n",
    "DISCOUNT = 0.99\n",
    "epsilon = 1\n",
    "EPSILON_DECAY = 0.95\n",
    "MIN_EPSILON = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override log file creation per .fit call to just 1 log file for all .fit calls\n",
    "class ModifiedTensorBoard(TensorBoard):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.step = 1\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "        \n",
    "    def set_model(self, model):\n",
    "        pass\n",
    "    \n",
    "    # Overrided, saves logs with our step number\n",
    "    # (otherwise every .fit() will start writing from 0th step)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.update_stats(**logs)\n",
    "\n",
    "    # Overrided\n",
    "    # We train for one batch only, no need to save anything at epoch end\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    # Overrided, so won't close writer\n",
    "    def on_train_end(self, _):\n",
    "        pass\n",
    "\n",
    "    # Custom method for saving own metrics\n",
    "    # Creates writer, writes custom metrics and closes writer\n",
    "    def update_stats(self, **stats):\n",
    "        self._write_logs(stats, self.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnv:\n",
    "    SHOW_CAM = SHOW_PREVIEW\n",
    "    STEER_AMT = 1.0\n",
    "    im_width = IM_WIDTH\n",
    "    im_height = IM_HEIGHT\n",
    "    front_camera = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = carla.Client('localhost', 2000)\n",
    "        self.client.set_timeout(2.0)\n",
    "        self.world = self.client.get_world()\n",
    "        self.blueprint_library = self.world.get_blueprint_library()\n",
    "        self.car_model = self.blueprint_library.filter('model3')[0]\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "        \n",
    "        \n",
    "    def reset(self):    \n",
    "        self.transform = random.choice(self.world.get_map().get_spawn_points())\n",
    "        self.vehicle = self.world.spawn_actor(self.car_model, self.transform)\n",
    "        self.actor_list.append(self.vehicle)\n",
    "        \n",
    "        self.rgb_cam = self.blueprint_library.find('sensor.camera.rgb')\n",
    "        self.rgb_cam.set_attribute('image_size_x', f'{self.im_width}')\n",
    "        self.rgb_cam.set_attribute('image_size_y', f'{self.im_height}')\n",
    "        self.rgb_cam.set_attribute('fov', f'110')\n",
    "        \n",
    "        transform = carla.Transform(carla.location(x=2.5, z=0.7)) # where to place sensor\n",
    "        self.sensor = self.world.spawn_actor(self.rgb_cam, transform)\n",
    "        \n",
    "        self.actor_list.append(self.sensor)\n",
    "        self.sensor.listen(lambda data: self.process_img(data))\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0)) # dont move\n",
    "        time.sleep(4)\n",
    "        \n",
    "        colsensor = self.blueprint_library.find('sensor.other.collision')\n",
    "        self.colsensor = self.world.spawn_actor(colsensor, transform, attach_to=self.vehicle)\n",
    "        self.colsensor.listen(lambda event: self.collision_data(event))\n",
    "        \n",
    "        self.actor_list.append(self.colsensor)\n",
    "        \n",
    "        while self.front_camera is None:\n",
    "            time.sleep(0.01)\n",
    "            \n",
    "        self.episode_start = time.time()\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0)) \n",
    "        \n",
    "        return self.front_camera\n",
    "    \n",
    "    def collision_data(self, event):\n",
    "        self.collision_hist.append(event) \n",
    "        \n",
    "    def process_img(image):\n",
    "        img_flat = np.array(image.raw_data)\n",
    "        img = img_flat.reshape(IM_HEIGHT, IM_WIDTH, 4)\n",
    "        img = img[:, :, :3] # ignores alpha values (images have 4 channels: rgba)\n",
    "        return img / 255.0\n",
    "        if self.SHOW_CAM:\n",
    "            cv2.imshow('', img)\n",
    "            cv2.waitKey(1)\n",
    "        self.front_camera = img\n",
    "        \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=-1*self.STEER_AMT))\n",
    "        elif action == 1:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0))\n",
    "        elif action == 2:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=self.STEER_AMT))\n",
    "        \n",
    "        v = self.vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "        \n",
    "        if len(self.collision_hist) != 0:\n",
    "            done = True\n",
    "            reward = -200\n",
    "        elif kmh < 50:\n",
    "            done = False\n",
    "            reward = -1\n",
    "        else:\n",
    "            done = False\n",
    "            reward = 1\n",
    "            \n",
    "        if self.episode_start + SECONDS_PER_EPISODE < time.time():\n",
    "            done = True\n",
    "        \n",
    "        return self.front_camera, reward, done, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.model = self.create_model() # train\n",
    "        self.target_model = self.create_model() # update periodically to self.model; used to keep results stable\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "        \n",
    "        self.tensorboard = ModifiedTensorBoard(log_dir=f'logs/{MODEL_NAME}-{int(time.time())}')\n",
    "        self.target_update_counter = 0\n",
    "        self.graph = tf.get_default_graph()\n",
    "        \n",
    "        self.terminate = False\n",
    "        self.last_logged_episode = 0\n",
    "        self.training_initialized = False\n",
    "        \n",
    "    def create_model(self):\n",
    "        base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        predictions = Dense(3, activation='linear')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def update_replay_memory(self, transition):\n",
    "        self.replay_memory.append(transition)\n",
    "        \n",
    "    def train(self):\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            return\n",
    "        \n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "        \n",
    "        current_states = np.array([transition[0] for transition in minibatch]) / 255.0\n",
    "        with self.graph.as_default():\n",
    "            current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE)\n",
    "            \n",
    "        new_current_states = np.array([transition[3] for transition in minibatch]) / 255.0\n",
    "        with self.graph.as_default():\n",
    "            future_qs_list = self.target_model.predict(new_current_states, PREDICTION_BATCH_SIZE)\n",
    "            \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for index, (current_state, action, reward, new_state, done) in enumerate(minibatch):\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "                \n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "            \n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "        \n",
    "        log_this_step = False\n",
    "        if self.tensorboard.step > self.last_logged_episode:\n",
    "            log_this_step = True\n",
    "            self.last_log_episode = self.tensorboard.step\n",
    "            \n",
    "        with self.graph.as_default():\n",
    "            self.model.fit(\n",
    "                np.array(X) / 255., \n",
    "                np.array(y), \n",
    "                batch_size=TRAINING_BATCH_SIZE, \n",
    "                verbose=0, \n",
    "                shuffle=False, \n",
    "                callbacks=[self.tensorboard] if log_this_step else None\n",
    "            )\n",
    "            \n",
    "        if log_this_step:\n",
    "            self.target_update_counter += 1\n",
    "        \n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "            \n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(np.array(state).reshape(-1, *state.shape) / 255.)[0]\n",
    "    \n",
    "    def train_in_loop(self):\n",
    "        # iterate through once to setup..\n",
    "        X = np.random.uniform(size=(1, IM_HEIGHT, IM_WIDTH, 3)).astype(np.float32)\n",
    "        y = np.random.uniform(size=(1, 3)).astype(np.float32)\n",
    "        with self.graph.as_default(): # apparently useless statement but good practice to prevent overlapping graph values\n",
    "            self.model.fit(X, y, verbose=False, batch_size=1)\n",
    "        \n",
    "        self.training_initialized = True\n",
    "        \n",
    "        while True:\n",
    "            if self.terminate:\n",
    "                break\n",
    "            self.train()\n",
    "            time.sleep(0.01)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 20\n",
    "ep_rewards = [-200]\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=MEMORY_FRACTION)\n",
    "backend.set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)))\n",
    "\n",
    "if not os.path.isdir('models'):\n",
    "    os.makedirs('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent()\n",
    "env = CarEnv()\n",
    "\n",
    "trainer_thread = Thread(target=agent.train_in_loop, daemon=True)\n",
    "trainer_thread.start()\n",
    "\n",
    "while not agent.training_initialized:\n",
    "    time.sleep(0.01)\n",
    "    \n",
    "agent.get_qs(np.ones((env.im_height, env.im_width, 3))) # mock image\n",
    "\n",
    "for episode in tqdm(range(1, EPISODES + 1), ascii=True, unit='episodes'):\n",
    "    env.collision_hist = []\n",
    "    agent.tensorboard.step = episode\n",
    "    episode_reward = 0\n",
    "    step = 1\n",
    "    current_state = env.reset()\n",
    "    done = False\n",
    "    episode_start = time.time()\n",
    "    \n",
    "    while True:\n",
    "        if np.random.random() > epsilon:\n",
    "            action = np.argmax(agent.get_qs(current_state))\n",
    "        else:\n",
    "            action = np.random.randint(0, 3)\n",
    "            time.sleep(1 / FPS)\n",
    "            \n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        episode_reward += reward\n",
    "        agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
    "        \n",
    "        # here we would add the train method  but since we are doing in parallel, another thread runs train_in_loop method\n",
    "        # idea is while running this loop, we somehow reach done; this may or may not actually initiate training\n",
    "        # eventually training will begin and we will continue adding new samples to training data\n",
    "        # the other thread continuously runs and will therefore continuously sample new training data for traning\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    for actor in env.actor_list:\n",
    "        actor.destroy()\n",
    "        env.actor_list = []\n",
    "        \n",
    "    ep_rewards.append(episode_reward)\n",
    "    if not episode % AGGREGATE_STATS_EVERY or episode == 1:\n",
    "        average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:]) / len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:]) / len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:]) / len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        agent.tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward, reward_max=max_reward)\n",
    "        \n",
    "        if min_reward >= MIN_REWARD:\n",
    "            agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg__{min_reward:_>7.2f}min.h5')\n",
    "        \n",
    "    \n",
    "    if epsilon > MIN_EPSILON:\n",
    "        epsilon = max(MIN_EPSILON, EPSILON_DECAY * epsilon)\n",
    "\n",
    "        \n",
    "agent.terminate = True\n",
    "trainer_thread.join()\n",
    "agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg__{min_reward:_>7.2f}min.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_list = []\n",
    "\n",
    "# try:\n",
    "#     # set up client\n",
    "#     client = carla.Client('localhost', 2000)\n",
    "#     client.set_timeout(2.0)\n",
    "    \n",
    "#     # set up vehicle\n",
    "#     world = client.get_world()\n",
    "#     blueprint_library = world.get_blueprint_library()\n",
    "#     bp = blueprint_library.filter('model3')[0]\n",
    "#     print(bp)\n",
    "    \n",
    "#     spawn_point = random.choice(world.get_map().get_spawn_points())\n",
    "    \n",
    "#     vehicle = world.spawn_actor(bp, spawn_point)\n",
    "# #     vehicle.set_autopilot(True)\n",
    "\n",
    "#     vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0.0))\n",
    "#     actor_list.append(vehicle)\n",
    "    \n",
    "#     # set up camera sensor\n",
    "#     cam_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "#     cam_bp.set_attribute('image_size_x', f'{IM_WIDTH}')\n",
    "#     cam_bp.set_attribute('image_size_y', f'{IM_HEIGHT}')\n",
    "#     cam_bp.set_attribute('fov', '110')\n",
    "    \n",
    "#     # place camera onto car\n",
    "#     spawn_point = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "#     sensor = world.spawn_actor(cam_bp, spawn_point, attach_to=vehicle)\n",
    "#     actor_list.append(sensor)\n",
    "#     sensor.listen(lambda data: process_img(data))\n",
    "# finally:\n",
    "#     pass\n",
    "\n",
    "# # clean up\n",
    "# for actor in actor_list:\n",
    "#     actor.destroy()\n",
    "# print('All cleaned up!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
