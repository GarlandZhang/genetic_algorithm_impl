{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as backend\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from threading import Thread\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('E:\\\\projects\\\\carla\\\\WindowsNoEditor\\\\PythonAPI\\\\carla\\\\dist\\\\carla-0.9.9-py3.7-win-amd64.egg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH = 640\n",
    "IM_HEIGHT = 480\n",
    "SHOW_PREVIEW = False\n",
    "SECONDS_PER_EPISODE = 10\n",
    "REPLAY_MEMORY_SIZE = 5_000\n",
    "MIN_REPLAY_MEMORY_SIZE = 1_000\n",
    "MINIBATCH_SIZE = 4\n",
    "PREDICTION_BATCH_SIZE = 1\n",
    "TRAINING_BATCH_SIZE = 2\n",
    "UPDATE_TARGET_EVERY = 5\n",
    "MODEL_NAME = 'Xception'\n",
    "\n",
    "MEMORY_FRACTION = 0.05\n",
    "MIN_REWARD = -200\n",
    "\n",
    "EPISODES = 100\n",
    "\n",
    "DISCOUNT = 0.99\n",
    "epsilon = 1\n",
    "EPSILON_DECAY = 0.95\n",
    "MIN_EPSILON = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override log file creation per .fit call to just 1 log file for all .fit calls\n",
    "class ModifiedTensorBoard(TensorBoard):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.step = 1\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "        \n",
    "    def set_model(self, model):\n",
    "        pass\n",
    "    \n",
    "    # Overrided, saves logs with our step number\n",
    "    # (otherwise every .fit() will start writing from 0th step)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.update_stats(**logs)\n",
    "\n",
    "    # Overrided\n",
    "    # We train for one batch only, no need to save anything at epoch end\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    # Overrided, so won't close writer\n",
    "    def on_train_end(self, _):\n",
    "        pass\n",
    "\n",
    "    # Custom method for saving own metrics\n",
    "    # Creates writer, writes custom metrics and closes writer\n",
    "    def update_stats(self, **stats):\n",
    "        self._write_logs(stats, self.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnv:\n",
    "    SHOW_CAM = SHOW_PREVIEW\n",
    "    STEER_AMT = 1.0\n",
    "    im_width = IM_WIDTH\n",
    "    im_height = IM_HEIGHT\n",
    "    front_camera = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = carla.Client('localhost', 2000)\n",
    "        self.world = self.client.get_world()\n",
    "        self.blueprint_library = self.world.get_blueprint_library()\n",
    "        self.car_model = self.blueprint_library.filter('model3')[0]\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "        \n",
    "        \n",
    "    def reset(self):    \n",
    "        self.transform = random.choice(self.world.get_map().get_spawn_points())\n",
    "        self.vehicle = self.world.spawn_actor(self.car_model, self.transform)\n",
    "        self.actor_list.append(self.vehicle)\n",
    "        \n",
    "        self.rgb_cam = self.blueprint_library.find('sensor.camera.rgb')\n",
    "        self.rgb_cam.set_attribute('image_size_x', f'{self.im_width}')\n",
    "        self.rgb_cam.set_attribute('image_size_y', f'{self.im_height}')\n",
    "        self.rgb_cam.set_attribute('fov', f'110')\n",
    "        \n",
    "        transform = carla.Transform(carla.location(x=2.5, z=0.7)) # where to place sensor\n",
    "        self.sensor = self.world.spawn_actor(self.rgb_cam, transform)\n",
    "        \n",
    "        self.actor_list.append(self.sensor)\n",
    "        self.sensor.listen(lambda data: self.process_img(data))\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0)) # dont move\n",
    "        time.sleep(4)\n",
    "        \n",
    "        colsensor = self.blueprint_library.find('sensor.other.collision')\n",
    "        self.colsensor = self.world.spawn_actor(colsensor, transform, attach_to=self.vehicle)\n",
    "        self.colsensor.listen(lambda event: self.collision_data(event))\n",
    "        \n",
    "        self.actor_list.append(self.colsensor)\n",
    "        \n",
    "        while self.front_camera is None:\n",
    "            time.sleep(0.01)\n",
    "            \n",
    "        self.episode_start = time.time()\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0)) \n",
    "        \n",
    "        return self.front_camera\n",
    "    \n",
    "    def collision_data(self, event):\n",
    "        self.collision_hist.append(event) \n",
    "        \n",
    "    def process_img(image):\n",
    "        img_flat = np.array(image.raw_data)\n",
    "        img = img_flat.reshape(IM_HEIGHT, IM_WIDTH, 4)\n",
    "        img = img[:, :, :3] # ignores alpha values (images have 4 channels: rgba)\n",
    "        return img / 255.0\n",
    "        if self.SHOW_CAM:\n",
    "            cv2.imshow('', img)\n",
    "            cv2.waitKey(1)\n",
    "        self.front_camera = img\n",
    "        \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=-1*self.STEER_AMT))\n",
    "        elif action == 1:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0))\n",
    "        elif action == 2:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=self.STEER_AMT))\n",
    "        \n",
    "        v = self.vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "        \n",
    "        if len(self.collision_hist) != 0:\n",
    "            done = True\n",
    "            reward = -200\n",
    "        elif kmh < 50:\n",
    "            done = False\n",
    "            reward = -1\n",
    "        else:\n",
    "            done = False\n",
    "            reward = 1\n",
    "            \n",
    "        if self.episode_start + SECONDS_PER_EPISODE < time.time():\n",
    "            done = True\n",
    "        \n",
    "        return self.front_camera, reward, done, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.sess = tf.Session()\n",
    "        set_session(self.sess)\n",
    "        self.model = self.create_model() # train\n",
    "        self.target_model = self.create_model() # update periodically to self.model; used to keep results stable\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "        \n",
    "        self.tensorboard = ModifiedTensorBoard(log_dir=f'logs/{MODEL_NAME}-{int(time.time())}')\n",
    "        self.target_update_counter = 0\n",
    "        self.graph = tf.get_default_graph()\n",
    "        \n",
    "        self.terminate = False\n",
    "        self.last_logged_episode = 0\n",
    "        self.training_initialized = False\n",
    "        \n",
    "    def create_model(self):\n",
    "        base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        predictions = Dense(3, activation='linear')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def update_replay_memory(self, transition):\n",
    "        self.replay_memory.append(transition)\n",
    "        \n",
    "    def train(self):\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            return\n",
    "        \n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "        \n",
    "        current_states = np.array([transition[0] for transition in minibatch]) / 255.0\n",
    "        with self.graph.as_default():\n",
    "            current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE)\n",
    "            \n",
    "        new_current_states = np.array([transition[3] for transition in minibatch]) / 255.0\n",
    "        with self.graph.as_default():\n",
    "            future_qs_list = self.target_model.predict(new_current_states, PREDICTION_BATCH_SIZE)\n",
    "            \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for index, (current_state, action, reward, new_state, done) in enumerate(minibatch):\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "                \n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "            \n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "        \n",
    "        log_this_step = False\n",
    "        if self.tensorboard.step > self.last_logged_episode:\n",
    "            log_this_step = True\n",
    "            self.last_log_episode = self.tensorboard.step\n",
    "            \n",
    "        with self.graph.as_default():\n",
    "            self.model.fit(\n",
    "                np.array(X) / 255., \n",
    "                np.array(y), \n",
    "                batch_size=TRAINING_BATCH_SIZE, \n",
    "                verbose=0, \n",
    "                shuffle=False, \n",
    "                callbacks=[self.tensorboard] if log_this_step else None\n",
    "            )\n",
    "            \n",
    "        if log_this_step:\n",
    "            self.target_update_counter += 1\n",
    "        \n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "            \n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(np.array(state).reshape(-1, *state.shape) / 255.)[0]\n",
    "    \n",
    "    def train_in_loop(self):\n",
    "        # iterate through once to setup..\n",
    "        X = np.random.uniform(size=(1, IM_HEIGHT, IM_WIDTH, 3)).astype(np.float32)\n",
    "        y = np.random.uniform(size=(1, 3)).astype(np.float32)\n",
    "        with self.graph.as_default(): # apparently useless statement but good practice to prevent overlapping graph values\n",
    "            set_session(self.sess)\n",
    "            self.model.fit(X, y, verbose=False, batch_size=1)\n",
    "        \n",
    "        self.training_initialized = True\n",
    "        \n",
    "        while True:\n",
    "            if self.terminate:\n",
    "                break\n",
    "            self.train()\n",
    "            time.sleep(0.01)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 20\n",
    "ep_rewards = [-200]\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=MEMORY_FRACTION)\n",
    "backend.set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)))\n",
    "\n",
    "if not os.path.isdir('models'):\n",
    "    os.makedirs('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,728,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node block6_sepconv2_1/depthwise_kernel/Initializer/random_uniform/RandomUniform (defined at C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\keras_applications\\xception.py:219) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'block6_sepconv2_1/depthwise_kernel/Initializer/random_uniform/RandomUniform', defined at:\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\asyncio\\base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-1f3a178c34ca>\", line 1, in <module>\n    agent = DQNAgent()\n  File \"<ipython-input-7-d6f3bf2ee9fc>\", line 6, in __init__\n    self.target_model = self.create_model() # update periodically to self.model; used to keep results stable\n  File \"<ipython-input-7-d6f3bf2ee9fc>\", line 20, in create_model\n    base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3))\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\", line 70, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\xception.py\", line 32, in Xception\n    return xception.Xception(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\keras_applications\\xception.py\", line 219, in Xception\n    name=prefix + '_sepconv2')(x)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 538, in __call__\n    self._maybe_build(inputs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1603, in _maybe_build\n    self.build(input_shapes)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 1334, in build\n    dtype=self.dtype)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 349, in add_weight\n    aggregation=aggregation)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\", line 607, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\", line 145, in make_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2488, in default_variable_creator\n    import_scope=import_scope)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 294, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 406, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\", line 127, in <lambda>\n    shape, dtype=dtype, partition_info=partition_info)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py\", line 512, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 247, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 777, in random_uniform\n    name=name)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,728,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node block6_sepconv2_1/depthwise_kernel/Initializer/random_uniform/RandomUniform (defined at C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\keras_applications\\xception.py:219) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,728,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node block6_sepconv2_1/depthwise_kernel/Initializer/random_uniform/RandomUniform}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1f3a178c34ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCarEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrainer_thread\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mThread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_in_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrainer_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-d6f3bf2ee9fc>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# update periodically to self.model; used to keep results stable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_memory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mREPLAY_MEMORY_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mget_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m       \u001b[0mweights\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m   2817\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2818\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2819\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2820\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2821\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    480\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m       \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[1;34m(session)\u001b[0m\n\u001b[0;32m    763\u001b[0m       \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m       \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,728,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node block6_sepconv2_1/depthwise_kernel/Initializer/random_uniform/RandomUniform (defined at C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\keras_applications\\xception.py:219) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'block6_sepconv2_1/depthwise_kernel/Initializer/random_uniform/RandomUniform', defined at:\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\asyncio\\base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-1f3a178c34ca>\", line 1, in <module>\n    agent = DQNAgent()\n  File \"<ipython-input-7-d6f3bf2ee9fc>\", line 6, in __init__\n    self.target_model = self.create_model() # update periodically to self.model; used to keep results stable\n  File \"<ipython-input-7-d6f3bf2ee9fc>\", line 20, in create_model\n    base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3))\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\__init__.py\", line 70, in wrapper\n    return base_fun(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\xception.py\", line 32, in Xception\n    return xception.Xception(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\keras_applications\\xception.py\", line 219, in Xception\n    name=prefix + '_sepconv2')(x)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 538, in __call__\n    self._maybe_build(inputs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1603, in _maybe_build\n    self.build(input_shapes)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 1334, in build\n    dtype=self.dtype)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 349, in add_weight\n    aggregation=aggregation)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\", line 607, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\", line 145, in make_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2488, in default_variable_creator\n    import_scope=import_scope)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 294, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 406, in _init_from_args\n    initial_value() if init_from_fn else initial_value,\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\", line 127, in <lambda>\n    shape, dtype=dtype, partition_info=partition_info)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py\", line 512, in __call__\n    shape, -limit, limit, dtype, seed=self.seed)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 247, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 777, in random_uniform\n    name=name)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,728,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node block6_sepconv2_1/depthwise_kernel/Initializer/random_uniform/RandomUniform (defined at C:\\Users\\GZhang\\Anaconda3\\lib\\site-packages\\keras_applications\\xception.py:219) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent()\n",
    "env = CarEnv()\n",
    "\n",
    "trainer_thread = Thread(target=agent.train_in_loop, daemon=True)\n",
    "trainer_thread.start()\n",
    "\n",
    "while not agent.training_initialized:\n",
    "    time.sleep(0.01)\n",
    "\n",
    "print('Agent training initialized')\n",
    "agent.get_qs(np.ones((env.im_height, env.im_width, 3))) # mock image\n",
    "\n",
    "for episode in tqdm(range(1, EPISODES + 1), ascii=True, unit='episodes'):\n",
    "    print('Episode: {}'.format(episode))\n",
    "    env.collision_hist = []\n",
    "    agent.tensorboard.step = episode\n",
    "    episode_reward = 0\n",
    "    step = 1\n",
    "    current_state = env.reset()\n",
    "    done = False\n",
    "    episode_start = time.time()\n",
    "    \n",
    "    while True:\n",
    "        if np.random.random() > epsilon:\n",
    "            action = np.argmax(agent.get_qs(current_state))\n",
    "        else:\n",
    "            action = np.random.randint(0, 3)\n",
    "            time.sleep(1 / FPS)\n",
    "            \n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        episode_reward += reward\n",
    "        agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
    "        \n",
    "        # here we would add the train method  but since we are doing in parallel, another thread runs train_in_loop method\n",
    "        # idea is while running this loop, we somehow reach done; this may or may not actually initiate training\n",
    "        # eventually training will begin and we will continue adding new samples to training data\n",
    "        # the other thread continuously runs and will therefore continuously sample new training data for traning\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    for actor in env.actor_list:\n",
    "        actor.destroy()\n",
    "        env.actor_list = []\n",
    "        \n",
    "    ep_rewards.append(episode_reward)\n",
    "    if not episode % AGGREGATE_STATS_EVERY or episode == 1:\n",
    "        average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:]) / len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:]) / len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:]) / len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        agent.tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward, reward_max=max_reward)\n",
    "        \n",
    "        if min_reward >= MIN_REWARD:\n",
    "            agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg__{min_reward:_>7.2f}min.h5')\n",
    "        \n",
    "    \n",
    "    if epsilon > MIN_EPSILON:\n",
    "        epsilon = max(MIN_EPSILON, EPSILON_DECAY * epsilon)\n",
    "\n",
    "        \n",
    "agent.terminate = True\n",
    "trainer_thread.join()\n",
    "agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg__{min_reward:_>7.2f}min.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_list = []\n",
    "\n",
    "# try:\n",
    "#     # set up client\n",
    "#     client = carla.Client('localhost', 2000)\n",
    "#     client.set_timeout(2.0)\n",
    "    \n",
    "#     # set up vehicle\n",
    "#     world = client.get_world()\n",
    "#     blueprint_library = world.get_blueprint_library()\n",
    "#     bp = blueprint_library.filter('model3')[0]\n",
    "#     print(bp)\n",
    "    \n",
    "#     spawn_point = random.choice(world.get_map().get_spawn_points())\n",
    "    \n",
    "#     vehicle = world.spawn_actor(bp, spawn_point)\n",
    "# #     vehicle.set_autopilot(True)\n",
    "\n",
    "#     vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0.0))\n",
    "#     actor_list.append(vehicle)\n",
    "    \n",
    "#     # set up camera sensor\n",
    "#     cam_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "#     cam_bp.set_attribute('image_size_x', f'{IM_WIDTH}')\n",
    "#     cam_bp.set_attribute('image_size_y', f'{IM_HEIGHT}')\n",
    "#     cam_bp.set_attribute('fov', '110')\n",
    "    \n",
    "#     # place camera onto car\n",
    "#     spawn_point = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "#     sensor = world.spawn_actor(cam_bp, spawn_point, attach_to=vehicle)\n",
    "#     actor_list.append(sensor)\n",
    "#     sensor.listen(lambda data: process_img(data))\n",
    "# finally:\n",
    "#     pass\n",
    "\n",
    "# # clean up\n",
    "# for actor in actor_list:\n",
    "#     actor.destroy()\n",
    "# print('All cleaned up!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
